# 计算机图形学大项目

## 项目内容

## 实现部分

### 摄像机系统

#### 透视投影

![ perspective_frustum](https://learnopengl-cn.github.io/img/01/08/perspective_frustum.png)

由于透视原理，两条线在很远的地方看起来是相交的。这是透视需要模仿的效果，同时这也是通过透视矩阵完成的。该矩阵可以修改每一个顶点的w值，距离观察者越远w分量便越大。而该矩阵还会将所有的顶点坐标映射到(-w, w)的范围上。
$$
out=\begin{bmatrix}
   x/w\\
   y/w \\
   z/w
  \end{bmatrix}
$$
与正交矩阵类似，我们可以调用GLM中的内置函数：

```
projection = glm::perspective(glm::radians(camera->Zoom), (float)windowsWidth / (float)windowsHeight, 0.1f, 100.0f);
```

其中，第一个参数fov定义了视野（Field of View），并且设置了观察空间的大小。第二个为宽高比，可以通过窗口的宽除以高得到。第三个和第四个参数定义了平截头体的近和远平面。近平面一般设为`1.0f`而远平面设为`100.0f`。如果顶点在近平面与远平面内，且处于平截头体内，则会被渲染。

#### LookAt矩阵

利用三个相互正交的向量，可以构件一个新的坐标空间，利用这三个轴另外加上一个平移向量可以创建一个矩阵。利用这个矩阵乘以任意向量可以变换到该坐标空间内
$$
LookAt=out=\begin{bmatrix}
   R_x & R_y & R_z & 0\\
   U_x & U_y & U_z & 0\\
   D_x & D_y & D_z & 0\\
  0 & 0 & 0 & 0
  \end{bmatrix} * 
  \begin{bmatrix}
   1 & 0 & 0 & -P_x\\
   0 & 1 & 0 & -P_y\\
   0 & 0 & 1 & -P_z\\
  0 & 0 & 0 & 1
  \end{bmatrix}
$$
#### 初始化属性值

```c++
// 属性值
    // 相机的位置
    glm::vec3 Position = glm::vec3(0.0f, 2.0f, 0.0f);
    // 相机的前向量
    glm::vec3 Front = glm::vec3(1.0f, 0.0f, 0.0f);
    // 相机的上向量
    glm::vec3 Up = glm::vec3(0.0f, 1.0f, 0.0f);
    // 相机的右向量
    glm::vec3 Right;
    // 观察坐标
    glm::vec3 WorldUp = glm::vec3(0.0f, 0.0f, 0.0f);
```

#### LookAt矩阵的使用

```c++
shaderManager->blockShader.use();
		glm::mat4 projection(1.0f);
		glm::mat4 view(1.0f);
		glm::mat4 model(1.0f);
		view = glm::lookAt(camera->Position, camera->Position + camera->Front, camera->Up);
		projection = glm::perspective(glm::radians(camera->Zoom), (float)windowsWidth / (float)windowsHeight, 0.1f, 100.0f);
		shaderManager->directionalLight.setMat4("projection", projection);
		shaderManager->directionalLight.setMat4("view", view);
```



#### 视觉移动

我们利用欧拉角（Euler Angle），通过在3D空间中旋转的三个值（pitch, yaw, roll）进行视角的移动。利用它们的结合，我们可以算出3D空间中的任何旋转的向量。

![img](https://learnopengl-cn.github.io/img/01/09/camera_pitch_yaw_roll.png)

这三个值的定义如下：

- 俯仰角，描述如何往上或往下看的角
- 偏航角，左右看的程度
- 滚转角，摄像机翻滚的程度

对于给定的俯仰角与偏航角，可以把其转换为代表新方向向量的3D向量。如下图：

![img](https://learnopengl-cn.github.io/img/01/09/camera_triangle.png)

其中的`hypotenuse = 1`。我们可以知道邻边的长度分别为 `cos x`与`sin y`。它们取决于所给的角度theta。同样地，我们通过下面的图片：

![img](https://learnopengl-cn.github.io/img/01/09/camera_pitch.png)

如果我们在xz平面上，向y轴看去，我们可以计算其长度y方向的强度（Strength）。对于给定的俯仰角theta，我们可以使用语句表示：

```
direction.y = sin(glm::radians(pitch));
```

同样地，我们需要更新x与z分量：

```
direction.x = cos(glm::radians(pitch));
direction.z = cos(glm::radians(pitch));
```

除此之外，我们还需要找到合适的分量计算偏航角。

![img](https://learnopengl-cn.github.io/img/01/09/camera_yaw.png)

如上图，x分量取决于`cos(yaw)`的值，z分量取决于`sin(yaw)`。摄像机位置移动后物体的投射投影方法上面的代码已经给出,这里不多说了。

#### 实现按键的移动

我们通过跟踪一个时间差（Deltatime），把所有速度乘以这个`deltaTime`值，可以调整移动速度。如果`deltaTime`值很大，那么上一帧渲染花费更多的时间，所以这一帧需要更高的速度进行平衡。

```c++
void escapePress(GLFWwindow *window, float& deltaTime) {
	if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)
		glfwSetWindowShouldClose(window, true);

	// 单独进行处理提高运算速度
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) {
		// WA
		// cout << "WA" << endl;
		camera->ProcessKeyboard(FORWARD_LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_D) == GLFW_RELEASE) {
		// W
		// cout << "W" << endl;
		camera->ProcessKeyboard(FORWARD, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) {
		// WD
		// cout << "WD" << endl;
		camera->ProcessKeyboard(FORWARD_RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) {
		// SA
		// cout << "SA" << endl;
		camera->ProcessKeyboard(BACKWARD_LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_A) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_D) == GLFW_RELEASE) {
		// S
		// cout << "S" << endl;
		camera->ProcessKeyboard(BACKWARD, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) {
		// SD
		// cout << "SD" << endl;
		camera->ProcessKeyboard(BACKWARD_RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_W) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_S) == GLFW_RELEASE) {
		// A
		// cout << "A" << endl;
		camera->ProcessKeyboard(LEFT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS && glfwGetKey(window, GLFW_KEY_W) == GLFW_RELEASE && glfwGetKey(window, GLFW_KEY_S) == GLFW_RELEASE) {
		// D
		// cout << "D" << endl;
		camera->ProcessKeyboard(RIGHT, deltaTime);
	}
	else if (glfwGetKey(window, GLFW_KEY_O) == GLFW_PRESS) {
		isPress = true;
	}
	else if (isPress && glfwGetKey(window, GLFW_KEY_O) == GLFW_RELEASE) {
		isPress = false;
		camera->ProcessKeyboard(FLYSKY, deltaTime);
	}
	// 跳跃单独处理
	if (glfwGetKey(window, GLFW_KEY_SPACE) == GLFW_PRESS)
		camera->ProcessKeyboard(JUMP, deltaTime);
	else if (glfwGetKey(window, GLFW_KEY_Q) == GLFW_PRESS) {
		camera->ProcessKeyboard(DOWN, deltaTime);
	}
}
```

其中`WSAD`四个按键控制摄像机前后左右移动，而对于同时按下两个键的情况，也同时考虑以提高位置更新的效率。如果用户按下`O`则打开**飞天模式**。在飞天模式中摄像机可以摆脱重力的束缚。

##### 按键移动的距离

根据此时按下的按键（可以是一个或者两个同时），可以对齐行走方向进行判断，如下：

```c++
if (direction == FORWARD)
        forwardVector += speed;
    if (direction == BACKWARD)
        forwardVector -= speed;
    if (direction == LEFT)
        rightVector -= speed;
    if (direction == RIGHT)
        rightVector += speed;
    if (direction == FORWARD_LEFT) {
        forwardVector += speed;
        rightVector -= speed;
    }
    if (direction == FORWARD_RIGHT) {
        forwardVector += speed;
        rightVector += speed;
    }
    if (direction == BACKWARD_LEFT) {
        forwardVector -= speed;
        rightVector -= speed;
    }
    if (direction == BACKWARD_RIGHT) {
        forwardVector -= speed;
        rightVector += speed;
    }
```

其中，`speed`为某一方向移动的距离，这里设为`2.0f`。而在这之后，根据当前摄像机的`前向量`以及`右向量`计算摄像机位置的位移量。当然，需要判断移动后位置的合法性（需要进行碰撞检测，而如果下方为空则自由落体）。如果用户处于飞天模式`flysky`为`true`，则直接进行碰撞检测即可。

```c++
 if (forwardVector != 0.0f || rightVector != 0.0f) {
        //行走不改变y轴坐标
        glm::mat4 vm = getViewMatrix();
        glm::vec3 forward = glm::vec3(vm[0][2], 0.0f, vm[2][2]);
        glm::vec3 strafe = glm::vec3(vm[0][0], 0.0f, vm[2][0]);

        afterMove = Position + (-forwardVector * forward + rightVector * strafe) * cameraSpeed;
        // 保留小数，减少计算量 0.001
        int remain = 3;
        if (abs(afterMove.x - Position.x) < 0.05f) {
            afterMove.x = Position.x;
        }
        if (abs(afterMove.z - Position.z) < 0.05f) {
            afterMove.z = Position.z;
        }
       // afterMove = glm::vec3(getFloat(afterMove.x, remain), getFloat(afterMove.y, remain), getFloat(afterMove.z, remain));
       //cout << "Pos:"<<Position.x << " " << Position.y << " " << Position.z << endl;
      //cout << "move:" << afterMove.x << " " << afterMove.y << " " << afterMove.z << endl;
       //afterMove = glm::vec3((int)afterMove.x, (int)afterMove.y, (int)afterMove.z);
        if (PhysicsEngine::getInstance()->HorizontalCollisionDetect(Position, afterMove)) {
            if (!engine->isFreeAll && !engine->isJumping && !flysky) {
                if (engine->WalkingVerticalCollisionDetect(afterMove)) {
                    //// 增加位移量
                    //float offset = 0.5f;
                    //int axBiggerthanPx = 0;
                    //int azBiggerthanPz = 0;
                    //if (afterMove.x < Position.x) {
                    //    axBiggerthanPx = -1;
                    //}
                    //else if (afterMove.x > Position.x) {
                    //    axBiggerthanPx = 1;
                    //}
                    //if (afterMove.z < Position.z) {
                    //    azBiggerthanPz = -1;
                    //}
                    //else if (afterMove.z > Position.z) {
                    //    azBiggerthanPz = 1;
                    //}
                    //float x_offset = axBiggerthanPx > 0 ? 1.0f : (axBiggerthanPx == 0 ? 0.0f : -1.0f);
                    //float z_offset = azBiggerthanPz > 0 ? 1.0f : (azBiggerthanPz == 0 ? 0.0f : -1.0f);

                    // Position = glm::vec3(afterMove.x + x_offset, Position.y, afterMove.z + z_offset);
                    Position = glm::vec3(afterMove.x, Position.y, afterMove.z);
                    FreeAll();
                    return;
                }
            }
            Position = afterMove;
        }
    }
```

### 光照

#### 点光源

phong光照模型由环境（Ambient）、漫反射（Diffuse）以及镜面（Sepcular）光照组成。

- 环境光照会改变光照的强度，实现物体的明暗效果
- 漫反射以及镜面光照则改变物体受光照的影响
  - 漫反射分量越大，物体对着光源的那部分就会越亮
  - 镜面光照分量越大则物体反光能力越强（越容易在物体表面上出现亮点）

段着色器（包括阴影）如下：

```c++
#version 450 core

out vec4 FragColor;

in VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} fs_in;

uniform sampler2D diffuseTexture;
uniform sampler2D shadowMap;

uniform vec3 lightColor;
uniform vec3 lightPos;
uniform vec3 viewPos;
// uniform vec3 objectColor;

uniform float ambientStrength;
uniform float specularStrength;
uniform float shininess;
uniform float diffuseFactor;


float ShadowCalculation(vec4 fragPosLightSpace, vec3 normal, vec3 lightDir)
{
    // 执行透视算法，将将w转化为(-1, 1)
    vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
    // 从(-1,1)变换到(0,1)
    projCoords = projCoords * 0.5 + 0.5;
    // 得到光的位置视野下最近的深度
    float closestDepth = texture(shadowMap, projCoords.xy).r; 
    // 简单获取投影向量的z坐标，等于来自光的透视视角的片元的深度
    float currentDepth = projCoords.z;

    // 避免阴影失真
    // 使用点乘
    float bias = max(0.5 * (1.0 - dot(normal, lightDir)), 0.005);

    // 从纹理像素四周对深度贴图采样，并取其平均值
    float shadow = 0.0;
    vec2 texelSize = 1.0 / textureSize(shadowMap, 0);
    for(int x = -1; x <= 1; ++x)
    {
        for(int y = -1; y <= 1; ++y)
        {
            float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r; 
            shadow += currentDepth - bias > pcfDepth  ? 1.0 : 0.0;
        }    
    }
    shadow /= 9.0;
    
    // 只投影向量的z坐标大于1.0则shadow的值强制设为0.0
    if(projCoords.z > 1.0){
        shadow = 0.0;
    }
    return shadow;
}

void main()
{
    // 进行材质处理，如果透明度小于0.1的片段丢弃
    vec4 texColor = texture(diffuseTexture, fs_in.TexCoords);
    if(texColor.a < 0.1)
        discard;
    vec3 objectColor = texture(diffuseTexture, fs_in.TexCoords).rgb;           
    vec3 normal = normalize(fs_in.Normal);
    //计算距离衰减
   
    // ambient环境光
    vec3 ambient =  ambientStrength * lightColor;
    // diffuse 漫反射
    vec3 lightDir = normalize(lightPos - fs_in.FragPos);
    float diff = max(dot(lightDir, normal), 0.0);
    vec3 diffuse = diff * lightColor * diffuseFactor;
    // specular 镜面
    vec3 viewDir = normalize(viewPos - fs_in.FragPos);
    vec3 reflectDir = reflect(-lightDir, normal);
    float spec = 0.0;
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    spec = pow(max(dot(normal, halfwayDir), 0.0), 64);
    vec3 specular = spec * lightColor * specularStrength;  

    // 计算阴影
    float shadow = ShadowCalculation(fs_in.FragPosLightSpace, normal, lightDir);                      
    vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * objectColor;
    FragColor = vec4(lighting, 1.0);
}
```

#### 环境光照

环境光照中，对于输入的环境因子`ambientStrength`，乘以输入的光照的颜色，可以得到环境光照`ambient`。该`ambient`变量乘以光照颜色可以得到片段的颜色（在计算结果中得到的仅仅是片段颜色的一部分）。

```c++
// ambient
vec3 ambient = ambientStrength * lightColor;
```

#### 漫反射

##### 坐标转换

首先，我们需要在顶点着色器中将输入的顶点位置坐标乘以模型矩阵，将其转变为世界看空间坐标。顶点着色器定义如下：

```c++
#version 450 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aNormal;
layout (location = 2) in vec2 aTexCoords;
layout (location = 3) in vec3 aOffset;

out vec2 TexCoords;

out VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} vs_out;

uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;
uniform mat4 lightSpaceMatrix;

void main()
{
    gl_Position = projection * view * model * vec4(aPos + aOffset, 1.0f);
    vs_out.FragPos = vec3(model * vec4(aPos, 1.0f));
    vs_out.Normal = transpose(inverse(mat3(model))) * aNormal;
    vs_out.TexCoords = aTexCoords;
    vs_out.FragPosLightSpace = lightSpaceMatrix * vec4(vs_out.FragPos, 1.0f);
    
}
```

因为法向量是一个方向向量而不能表达空间中的特定位置（坐标），所以我们通过法线矩阵进行法向量向世界坐标的变换。在运用中，我们使用`inverse`以及`transpose`函数生成发现矩阵。

```c++
Normal = mat3(transpose(inverse(model))) * aNormal;  
```

##### 利用法向量进行计算

漫反射能够对物体产生显著的视觉影响。对于在程序中手动输入并且传到段着色器中的法向量`Normal Factor`（法向量为垂直于顶点表面的单位向量），我们还需要有如下的操作：

- 计算光源位置与片段位置之间的方向向量，即光的方向向量。
- 将光的方向向量进行标准化，因为我们只关注方向。
- 将标准化后的法向量`norm`与光的方向向量`lightDir`进行点乘，计算出光源对当前片段的漫反射影响。
  - 如果两个向量的角度越大，点乘的结果越小，则漫反射分量越小。
- 进行合法性判断，如果点乘结果小于零则置为0（角度大于90度时为负数）。
- 计算结果乘以物体颜色以及漫反射参数`diffuseFactor`，得到结果。

```c++
    // diffuse 
    vec3 norm = normalize(Normal);
    vec3 lightDir = normalize(lightPos - FragPos);
    float diff = max(dot(norm, lightDir), 0.0);
    vec3 diffuse = diff * lightColor * diffuseFactor;
```

#### 镜面光照

镜面光照与光的方向向量以及物体的法向量决定，它与观察向量也是有关的。我们通过法向量计算其反射向量，再计算反射向量与视线方向的角度差。夹角越小则镜面光的影响越大（产生高光）。

在段着色器中，我们需要更改其镜面因素`specularStrength`。同时，我们还需对`lightDir`进行取反，而`reflect`函数需要第一个向量是从光源指向片段位置的向量，第二个则是标准化后的法向量。计算的时候，需要注意视线方向与反射方向向量的点乘需要确保大于或等于0，之后取幂值（幂值为输入的`shininess`变量，称反光度。如果反光度越高，反射光能力越强，散射越小，同时高光的点越小。）

```c++
// specular
    vec3 viewDir = normalize(viewPos - FragPos);
    vec3 reflectDir = reflect(-lightDir, norm);  
    float spec = pow(max(dot(viewDir, reflectDir), 0.0), shininess);
    vec3 specular = specularStrength * spec * lightColor;  
```

最后，算出了全部分量。

```c++
vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * objectColor;
FragColor = vec4(lighting, 1.0);
```

#### 平行光



### 实例化数组

// 还没写报告

### 纹理贴图

// 还没写报告

### 阴影

// 还没写报告

### 模型导入 

// 还没写报告

### 天空盒



### 重力系统与碰撞检测

// 还没写报告

#### 弹跳

// 还没写报告

#### 自由落体

// 还没写报告

### Gamma矫正

// 还没写报告